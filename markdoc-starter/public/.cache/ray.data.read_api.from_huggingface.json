{
    "name": "ray.data.read_api.from_huggingface",
    "signature": "ray.data.read_api.from_huggingface(dataset: Union[ForwardRef('datasets.Dataset'), ForwardRef('datasets.IterableDataset')], parallelism: int = -1, concurrency: Optional[int] = None, override_num_blocks: Optional[int] = None) -> Union[ray.data.dataset.MaterializedDataset, ray.data.dataset.Dataset]",
    "summary": "Create a :class:`~ray.data.MaterializedDataset` from a",
    "desc": "`Hugging Face Datasets Dataset <https://huggingface.co/docs/datasets/package_reference/main_classes#datasets.Dataset/>`_\nor a :class:`~ray.data.Dataset` from a `Hugging Face Datasets IterableDataset <https://huggingface.co/docs/datasets/package_reference/main_classes#datasets.IterableDataset/>`_.\nFor an `IterableDataset`, we use a streaming implementation to read data.\n\nIf the dataset is a public Hugging Face Dataset that is hosted on the Hugging Face Hub and\nno transformations have been applied, then the `hosted parquet files <https://huggingface.co/docs/datasets-server/parquet#list-parquet-files>`_\nwill be passed to :meth:`~ray.data.read_parquet` to perform a distributed read. All\nother cases will be done with a single node read.",
    "args": [
        {
            "name": "dataset",
            "type": null,
            "desc": "A `Hugging Face Datasets Dataset`_ or `Hugging Face Datasets IterableDataset`_.\n`DatasetDict <https://huggingface.co/docs/datasets/package_reference/main_classes#datasets.DatasetDict/>`_\nand `IterableDatasetDict <https://huggingface.co/docs/datasets/package_reference/main_classes#datasets.IterableDatasetDict/>`_\nare not supported."
        },
        {
            "name": "parallelism",
            "type": null,
            "desc": "This argument is deprecated. Use ``override_num_blocks`` argument."
        },
        {
            "name": "concurrency",
            "type": null,
            "desc": "The maximum number of Ray tasks to run concurrently. Set this\nto control number of tasks to run concurrently. This doesn't change the\ntotal number of tasks run or the total number of output blocks. By default,\nconcurrency is dynamically decided based on the available resources."
        },
        {
            "name": "override_num_blocks",
            "type": null,
            "desc": "Override the number of output blocks from all read tasks.\nBy default, the number of output blocks is dynamically decided based on\ninput data size and available resources. You shouldn't manually set this\nvalue in most cases."
        }
    ],
    "returns": "A :class:`~ray.data.Dataset` holding rows from the `Hugging Face Datasets Dataset`_.",
    "examples": [
        {
            "desc": null,
            "code": "..\n    The following `testoutput` is mocked to avoid illustrating download\n    logs like \"Downloading and preparing dataset 162.17 MiB\".\n\n.. testcode::\n\n    import ray\n    import datasets\n\n    hf_dataset = datasets.load_dataset(\"tweet_eval\", \"emotion\")\n    ray_ds = ray.data.from_huggingface(hf_dataset[\"train\"])\n    print(ray_ds)\n\n    hf_dataset_stream = datasets.load_dataset(\"tweet_eval\", \"emotion\", streaming=True)\n    ray_ds_stream = ray.data.from_huggingface(hf_dataset_stream[\"train\"])\n    print(ray_ds_stream)\n\n.. testoutput::\n    :options: +MOCK\n\n    MaterializedDataset(\n        num_blocks=...,\n        num_rows=3257,\n        schema={text: string, label: int64}\n    )\n    Dataset(\n        num_rows=3257,\n        schema={text: string, label: int64}\n    )"
        }
    ]
}