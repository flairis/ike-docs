{
    "name": "ray.data.read_api.read_csv",
    "signature": "ray.data.read_api.read_csv(paths: Union[str, List[str]], *, filesystem: Optional[ForwardRef('pyarrow.fs.FileSystem')] = None, parallelism: int = -1, ray_remote_args: Dict[str, Any] = None, arrow_open_stream_args: Optional[Dict[str, Any]] = None, meta_provider: Optional[ray.data.datasource.file_meta_provider.BaseFileMetadataProvider] = None, partition_filter: Optional[ray.data.datasource.partitioning.PathPartitionFilter] = None, partitioning: ray.data.datasource.partitioning.Partitioning = Partitioning(style='hive', base_dir='', field_names=None, field_types={}, filesystem=None), include_paths: bool = False, ignore_missing_paths: bool = False, shuffle: Optional[Literal['files']] = None, file_extensions: Optional[List[str]] = None, concurrency: Optional[int] = None, override_num_blocks: Optional[int] = None, **arrow_csv_args) -> ray.data.dataset.Dataset",
    "summary": "Creates a :class:`~ray.data.Dataset` from CSV files.",
    "desc": null,
    "args": [
        {
            "name": "paths",
            "type": null,
            "desc": "A single file or directory, or a list of file or directory paths.\nA list of paths can contain both files and directories."
        },
        {
            "name": "filesystem",
            "type": null,
            "desc": "The PyArrow filesystem\nimplementation to read from. These filesystems are specified in the\n`pyarrow docs <https://arrow.apache.org/docs/python/api/            filesystems.html#filesystem-implementations>`_. Specify this parameter if\nyou need to provide specific configurations to the filesystem. By default,\nthe filesystem is automatically selected based on the scheme of the paths.\nFor example, if the path begins with ``s3://``, the `S3FileSystem` is used."
        },
        {
            "name": "parallelism",
            "type": null,
            "desc": "This argument is deprecated. Use ``override_num_blocks`` argument."
        },
        {
            "name": "ray_remote_args",
            "type": null,
            "desc": "kwargs passed to :meth:`~ray.remote` in the read tasks."
        },
        {
            "name": "arrow_open_stream_args",
            "type": null,
            "desc": "kwargs passed to\n`pyarrow.fs.FileSystem.open_input_file <https://arrow.apache.org/docs/                python/generated/pyarrow.fs.FileSystem.html                    #pyarrow.fs.FileSystem.open_input_stream>`_.\nwhen opening input files to read."
        },
        {
            "name": "meta_provider",
            "type": null,
            "desc": "A :ref:`file metadata provider <metadata_provider>`. Custom\nmetadata providers may be able to resolve file metadata more quickly and/or\naccurately. In most cases, you do not need to set this. If ``None``, this\nfunction uses a system-chosen implementation."
        },
        {
            "name": "partition_filter",
            "type": null,
            "desc": "A\n:class:`~ray.data.datasource.partitioning.PathPartitionFilter`.\nUse with a custom callback to read only selected partitions of a\ndataset. By default, no files are filtered."
        },
        {
            "name": "partitioning",
            "type": null,
            "desc": "A :class:`~ray.data.datasource.partitioning.Partitioning` object\nthat describes how paths are organized. By default, this function parses\n`Hive-style partitions <https://athena.guide/articles/                hive-style-partitioning/>`_."
        },
        {
            "name": "include_paths",
            "type": null,
            "desc": "If ``True``, include the path to each file. File paths are\nstored in the ``'path'`` column."
        },
        {
            "name": "ignore_missing_paths",
            "type": null,
            "desc": "If True, ignores any file paths in ``paths`` that are not\nfound. Defaults to False."
        },
        {
            "name": "shuffle",
            "type": null,
            "desc": "If setting to \"files\", randomly shuffle input files order before read.\nDefaults to not shuffle with ``None``."
        },
        {
            "name": "arrow_csv_args",
            "type": null,
            "desc": "CSV read options to pass to\n`pyarrow.csv.open_csv <https://arrow.apache.org/docs/python/generated/            pyarrow.csv.open_csv.html#pyarrow.csv.open_csv>`_\nwhen opening CSV files."
        },
        {
            "name": "file_extensions",
            "type": null,
            "desc": "A list of file extensions to filter files by."
        },
        {
            "name": "concurrency",
            "type": null,
            "desc": "The maximum number of Ray tasks to run concurrently. Set this\nto control number of tasks to run concurrently. This doesn't change the\ntotal number of tasks run or the total number of output blocks. By default,\nconcurrency is dynamically decided based on the available resources."
        },
        {
            "name": "override_num_blocks",
            "type": null,
            "desc": "Override the number of output blocks from all read tasks.\nBy default, the number of output blocks is dynamically decided based on\ninput data size and available resources. You shouldn't manually set this\nvalue in most cases."
        }
    ],
    "returns": ":class:`~ray.data.Dataset` producing records read from the specified paths.",
    "examples": [
        {
            "desc": null,
            "code": "Read a file in remote storage.\n\n>>> import ray\n>>> ds = ray.data.read_csv(\"s3://anonymous@ray-example-data/iris.csv\")\n>>> ds.schema()\nColumn             Type\n------             ----\nsepal length (cm)  double\nsepal width (cm)   double\npetal length (cm)  double\npetal width (cm)   double\ntarget             int64\n\nRead multiple local files.\n\n>>> ray.data.read_csv( # doctest: +SKIP\n...    [\"local:///path/to/file1\", \"local:///path/to/file2\"])\n\nRead a directory from remote storage.\n\n>>> ds = ray.data.read_csv(\"s3://anonymous@ray-example-data/iris-csv/\")\n\nRead files that use a different delimiter. For more uses of ParseOptions see\nhttps://arrow.apache.org/docs/python/generated/pyarrow.csv.ParseOptions.html  # noqa: #501\n\n>>> from pyarrow import csv\n>>> parse_options = csv.ParseOptions(delimiter=\"\\t\")\n>>> ds = ray.data.read_csv(\n...     \"s3://anonymous@ray-example-data/iris.tsv\",\n...     parse_options=parse_options)\n>>> ds.schema()\nColumn        Type\n------        ----\nsepal.length  double\nsepal.width   double\npetal.length  double\npetal.width   double\nvariety       string\n\nConvert a date column with a custom format from a CSV file. For more uses of ConvertOptions see https://arrow.apache.org/docs/python/generated/pyarrow.csv.ConvertOptions.html  # noqa: #501\n\n>>> from pyarrow import csv\n>>> convert_options = csv.ConvertOptions(\n...     timestamp_parsers=[\"%m/%d/%Y\"])\n>>> ds = ray.data.read_csv(\n...     \"s3://anonymous@ray-example-data/dow_jones.csv\",\n...     convert_options=convert_options)\n\nBy default, :meth:`~ray.data.read_csv` parses\n`Hive-style partitions <https://athena.guide/        articles/hive-style-partitioning/>`_\nfrom file paths. If your data adheres to a different partitioning scheme, set\nthe ``partitioning`` parameter.\n\n>>> ds = ray.data.read_csv(\"s3://anonymous@ray-example-data/year=2022/month=09/sales.csv\")\n>>> ds.take(1)\n[{'order_number': 10107, 'quantity': 30, 'year': '2022', 'month': '09'}]\n\nBy default, :meth:`~ray.data.read_csv` reads all files from file paths. If you want to filter\nfiles by file extensions, set the ``file_extensions`` parameter.\n\nRead only ``*.csv`` files from a directory.\n\n>>> ray.data.read_csv(\"s3://anonymous@ray-example-data/different-extensions/\",\n...     file_extensions=[\"csv\"])\nDataset(num_rows=?, schema={a: int64, b: int64})"
        }
    ]
}