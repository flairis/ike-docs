{
    "name": "ray.data.read_api.from_spark",
    "signature": "ray.data.read_api.from_spark(df: 'pyspark.sql.DataFrame', *, parallelism: Optional[int] = None, override_num_blocks: Optional[int] = None) -> ray.data.dataset.MaterializedDataset",
    "summary": "Create a :class:`~ray.data.Dataset` from a",
    "desc": "`Spark DataFrame <https://spark.apache.org/docs/3.1.1/api/python/reference/api/pyspark.sql.DataFrame.html>`_.",
    "args": [
        {
            "name": "df",
            "type": null,
            "desc": "A `Spark DataFrame`_, which must be created by RayDP (Spark-on-Ray)."
        },
        {
            "name": "parallelism",
            "type": null,
            "desc": "This argument is deprecated. Use ``override_num_blocks`` argument."
        },
        {
            "name": "override_num_blocks",
            "type": null,
            "desc": "Override the number of output blocks from all read tasks.\nBy default, the number of output blocks is dynamically decided based on\ninput data size and available resources. You shouldn't manually set this\nvalue in most cases."
        }
    ],
    "returns": "A :class:`~ray.data.MaterializedDataset` holding rows read from the DataFrame.",
    "examples": []
}