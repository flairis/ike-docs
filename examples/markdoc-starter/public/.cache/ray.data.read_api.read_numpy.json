{
    "name": "ray.data.read_api.read_numpy",
    "signature": "ray.data.read_api.read_numpy(paths: Union[str, List[str]], *, filesystem: Optional[ForwardRef('pyarrow.fs.FileSystem')] = None, parallelism: int = -1, arrow_open_stream_args: Optional[Dict[str, Any]] = None, meta_provider: Optional[ray.data.datasource.file_meta_provider.BaseFileMetadataProvider] = None, partition_filter: Optional[ray.data.datasource.partitioning.PathPartitionFilter] = None, partitioning: ray.data.datasource.partitioning.Partitioning = None, include_paths: bool = False, ignore_missing_paths: bool = False, shuffle: Optional[Literal['files']] = None, file_extensions: Optional[List[str]] = ['npy'], concurrency: Optional[int] = None, override_num_blocks: Optional[int] = None, **numpy_load_args) -> ray.data.dataset.Dataset",
    "summary": "Create an Arrow dataset from numpy files.",
    "desc": null,
    "args": [
        {
            "name": "paths",
            "type": null,
            "desc": "A single file/directory path or a list of file/directory paths.\nA list of paths can contain both files and directories."
        },
        {
            "name": "filesystem",
            "type": null,
            "desc": "The filesystem implementation to read from."
        },
        {
            "name": "parallelism",
            "type": null,
            "desc": "This argument is deprecated. Use ``override_num_blocks`` argument."
        },
        {
            "name": "arrow_open_stream_args",
            "type": null,
            "desc": "kwargs passed to\n`pyarrow.fs.FileSystem.open_input_stream <https://arrow.apache.org/docs/python/generated/pyarrow.fs.FileSystem.html>`_."
        },
        {
            "name": "numpy_load_args",
            "type": null,
            "desc": "Other options to pass to np.load."
        },
        {
            "name": "meta_provider",
            "type": null,
            "desc": "File metadata provider. Custom metadata providers may\nbe able to resolve file metadata more quickly and/or accurately. If\n``None``, this function uses a system-chosen implementation."
        },
        {
            "name": "partition_filter",
            "type": null,
            "desc": "Path-based partition filter, if any. Can be used\nwith a custom callback to read only selected partitions of a dataset.\nBy default, this filters out any file paths whose file extension does not\nmatch \"*.npy*\"."
        },
        {
            "name": "partitioning",
            "type": null,
            "desc": "A :class:`~ray.data.datasource.partitioning.Partitioning` object\nthat describes how paths are organized. Defaults to ``None``."
        },
        {
            "name": "include_paths",
            "type": null,
            "desc": "If ``True``, include the path to each file. File paths are\nstored in the ``'path'`` column."
        },
        {
            "name": "ignore_missing_paths",
            "type": null,
            "desc": "If True, ignores any file paths in ``paths`` that are not\nfound. Defaults to False."
        },
        {
            "name": "shuffle",
            "type": null,
            "desc": "If setting to \"files\", randomly shuffle input files order before read.\nDefaults to not shuffle with ``None``."
        },
        {
            "name": "file_extensions",
            "type": null,
            "desc": "A list of file extensions to filter files by."
        },
        {
            "name": "concurrency",
            "type": null,
            "desc": "The maximum number of Ray tasks to run concurrently. Set this\nto control number of tasks to run concurrently. This doesn't change the\ntotal number of tasks run or the total number of output blocks. By default,\nconcurrency is dynamically decided based on the available resources."
        },
        {
            "name": "override_num_blocks",
            "type": null,
            "desc": "Override the number of output blocks from all read tasks.\nBy default, the number of output blocks is dynamically decided based on\ninput data size and available resources. You shouldn't manually set this\nvalue in most cases."
        }
    ],
    "returns": "Dataset holding Tensor records read from the specified paths.",
    "examples": [
        {
            "desc": null,
            "code": "Read a directory of files in remote storage.\n\n>>> import ray\n>>> ray.data.read_numpy(\"s3://bucket/path\") # doctest: +SKIP\n\nRead multiple local files.\n\n>>> ray.data.read_numpy([\"/path/to/file1\", \"/path/to/file2\"]) # doctest: +SKIP\n\nRead multiple directories.\n\n>>> ray.data.read_numpy( # doctest: +SKIP\n...     [\"s3://bucket/path1\", \"s3://bucket/path2\"])"
        }
    ]
}