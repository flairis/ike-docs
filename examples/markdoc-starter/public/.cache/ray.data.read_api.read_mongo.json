{
    "name": "ray.data.read_api.read_mongo",
    "signature": "ray.data.read_api.read_mongo(uri: str, database: str, collection: str, *, pipeline: Optional[List[Dict]] = None, schema: Optional[ForwardRef('pymongoarrow.api.Schema')] = None, parallelism: int = -1, ray_remote_args: Dict[str, Any] = None, concurrency: Optional[int] = None, override_num_blocks: Optional[int] = None, **mongo_args) -> ray.data.dataset.Dataset",
    "summary": "Create a :class:`~ray.data.Dataset` from a MongoDB database.",
    "desc": "The data to read from is specified via the ``uri``, ``database`` and ``collection``\nof the MongoDB. The dataset is created from the results of executing\n``pipeline`` against the ``collection``. If ``pipeline`` is None, the entire\n``collection`` is read.\n\n.. tip::\n\n    For more details about these MongoDB concepts, see the following:\n    - URI: https://www.mongodb.com/docs/manual/reference/connection-string/\n    - Database and Collection: https://www.mongodb.com/docs/manual/core/databases-and-collections/\n    - Pipeline: https://www.mongodb.com/docs/manual/core/aggregation-pipeline/\n\nTo read the MongoDB in parallel, the execution of the pipeline is run on partitions\nof the collection, with a Ray read task to handle a partition. Partitions are\ncreated in an attempt to evenly distribute the documents into the specified number\nof partitions. The number of partitions is determined by ``parallelism`` which can\nbe requested from this interface or automatically chosen if unspecified (see the\n``parallelism`` arg below).",
    "args": [
        {
            "name": "uri",
            "type": null,
            "desc": "The URI of the source MongoDB where the dataset is\nread from. For the URI format, see details in the `MongoDB docs <https:/                /www.mongodb.com/docs/manual/reference/connection-string/>`_."
        },
        {
            "name": "database",
            "type": null,
            "desc": "The name of the database hosted in the MongoDB. This database\nmust exist otherwise ValueError is raised."
        },
        {
            "name": "collection",
            "type": null,
            "desc": "The name of the collection in the database. This collection\nmust exist otherwise ValueError is raised."
        },
        {
            "name": "pipeline",
            "type": null,
            "desc": "A `MongoDB pipeline <https://www.mongodb.com/docs/manual/core            /aggregation-pipeline/>`_, which is executed on the given collection\nwith results used to create Dataset. If None, the entire collection will\nbe read."
        },
        {
            "name": "schema",
            "type": null,
            "desc": "The schema used to read the collection. If None, it'll be inferred from\nthe results of pipeline."
        },
        {
            "name": "parallelism",
            "type": null,
            "desc": "This argument is deprecated. Use ``override_num_blocks`` argument."
        },
        {
            "name": "ray_remote_args",
            "type": null,
            "desc": "kwargs passed to :meth:`~ray.remote` in the read tasks."
        },
        {
            "name": "concurrency",
            "type": null,
            "desc": "The maximum number of Ray tasks to run concurrently. Set this\nto control number of tasks to run concurrently. This doesn't change the\ntotal number of tasks run or the total number of output blocks. By default,\nconcurrency is dynamically decided based on the available resources."
        },
        {
            "name": "override_num_blocks",
            "type": null,
            "desc": "Override the number of output blocks from all read tasks.\nBy default, the number of output blocks is dynamically decided based on\ninput data size and available resources. You shouldn't manually set this\nvalue in most cases."
        },
        {
            "name": "mongo_args",
            "type": null,
            "desc": "kwargs passed to `aggregate_arrow_all() <https://mongo-arrow            .readthedocs.io/en/latest/api/api.html#pymongoarrow.api            aggregate_arrow_all>`_ in pymongoarrow in producing\nArrow-formatted results."
        }
    ],
    "returns": ":class:`~ray.data.Dataset` producing rows from the results of executing the pipeline on the specified MongoDB collection.",
    "examples": [
        {
            "desc": null,
            "code": ">>> import ray\n>>> from pymongoarrow.api import Schema # doctest: +SKIP\n>>> ds = ray.data.read_mongo( # doctest: +SKIP\n...     uri=\"mongodb://username:password@mongodb0.example.com:27017/?authSource=admin\", # noqa: E501\n...     database=\"my_db\",\n...     collection=\"my_collection\",\n...     pipeline=[{\"$match\": {\"col2\": {\"$gte\": 0, \"$lt\": 100}}}, {\"$sort\": \"sort_field\"}], # noqa: E501\n...     schema=Schema({\"col1\": pa.string(), \"col2\": pa.int64()}),\n...     override_num_blocks=10,\n... )"
        }
    ]
}